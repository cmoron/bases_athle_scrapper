# Refactorisation du projet Bases Athl√©

## üìã Contexte

Suite aux changements majeurs du site bases.athle.fr :
- Nouvelles URLs pour les pages athl√®tes et clubs
- Changement des IDs athl√®tes (overlaps possibles entre anciens et nouveaux IDs)
- Nouveau format HTML

**D√©cision** : Refactorisation compl√®te avec nouvelle architecture de base de donn√©es.

---

## üéØ Objectifs de la refactorisation

1. ‚úÖ **IDs internes auto-g√©n√©r√©s** - Plus de conflits possibles
2. ‚úÖ **`license_id` comme cl√© m√©tier** - Identifiant stable et fiable
3. ‚úÖ **`normalized_name` pour recherche performante** - Index trigram pour recherches floues rapides
4. ‚úÖ **Gestion des logs am√©lior√©e** - Rotation automatique et archivage
5. ‚úÖ **Architecture modulaire** - Code organis√© en modules (scraper/, tools/)

---

## üèóÔ∏è Nouvelle architecture

```
mypacer_scraper/
‚îú‚îÄ‚îÄ core/                       # ‚úÖ Module fondamental
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ db.py                   # ‚úÖ Connexion base de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # ‚úÖ Configuration logs am√©lior√©e
‚îÇ   ‚îú‚îÄ‚îÄ schema.py               # ‚úÖ Gestion du sch√©ma
‚îÇ   ‚îî‚îÄ‚îÄ schema.sql              # ‚úÖ D√©finition du sch√©ma SQL
‚îú‚îÄ‚îÄ scraper/                    # Module de scraping
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ list_athletes.py        # Script de scraping athl√®tes
‚îÇ   ‚îî‚îÄ‚îÄ list_clubs.py           # Script de scraping clubs
‚îú‚îÄ‚îÄ tools/                      # Outils d'analyse et maintenance
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ analyze_database.py     # ‚úÖ Script d'analyse consolid√©
‚îú‚îÄ‚îÄ tests/                      # Tests unitaires
‚îÇ   ‚îú‚îÄ‚îÄ test_duplicate_handling.py
‚îÇ   ‚îî‚îÄ‚îÄ test_storage.py
‚îú‚îÄ‚îÄ logs/                       # Logs avec rotation automatique
‚îÇ   ‚îú‚îÄ‚îÄ archive/                # Anciens logs archiv√©s
‚îÇ   ‚îî‚îÄ‚îÄ *.log                   # Logs actifs (5 derniers)
‚îú‚îÄ‚îÄ update_database.sh          # Script principal de mise √† jour
‚îî‚îÄ‚îÄ README.md
```

---

## üìä Nouveau sch√©ma de base de donn√©es

### Table `athletes`

```sql
CREATE TABLE athletes (
    id SERIAL PRIMARY KEY,                    -- ‚úÖ ID interne auto-increment
    ffa_id TEXT NOT NULL UNIQUE,              -- ID FFA (abstrait)
    license_id TEXT,                          -- Num√©ro de licence (cl√© m√©tier)
    name TEXT NOT NULL,
    normalized_name TEXT NOT NULL,            -- ‚úÖ Pour recherche rapide
    url TEXT,
    birth_date TEXT,
    sexe TEXT,
    nationality TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Index unique partiel : garantit qu'un license_id valide ne peut exister qu'une fois
CREATE UNIQUE INDEX idx_athletes_license_id_unique ON athletes(license_id)
    WHERE license_id IS NOT NULL
      AND license_id != ''
      AND license_id != '-'
      AND license_id != 'None';
```

**Index cr√©√©s** :
- `idx_athletes_ffa_id` - Recherche par ID FFA
- `idx_athletes_license_id_unique` - ‚úÖ **Index unique partiel** sur license_id (exclut valeurs invalides)
- `idx_athletes_normalized_name_trgm` - Recherche floue ultra-rapide (GIN trigram)
- `idx_athletes_license_id` - Recherche par num√©ro de licence
- Autres index sur sexe, birth_date, etc.

### Table `clubs`

```sql
CREATE TABLE clubs (
    id SERIAL PRIMARY KEY,
    ffa_id TEXT NOT NULL UNIQUE,
    name TEXT NOT NULL,
    normalized_name TEXT NOT NULL,
    first_year INTEGER,
    last_year INTEGER,
    url TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

### Triggers automatiques

- `trigger_update_athlete_normalized_name` - Met √† jour automatiquement `normalized_name` et `updated_at`
- `trigger_update_club_normalized_name` - Idem pour clubs

### Vues utiles

- `v_athletes_stats` - Statistiques globales sur les athl√®tes
- `v_clubs_stats` - Statistiques globales sur les clubs

---

## üîß Am√©liorations apport√©es

### 1. Gestion des logs (`core/config.py`)

**Avant** :
- Un seul fichier `scrapping.log`
- Pas de rotation
- Logs qui grossissent ind√©finiment

**Apr√®s** :
```python
from core.config import setup_logging
setup_logging('update_database')  # Cr√©e update_database_20251115_174530.log
```

‚úÖ **Fonctionnalit√©s** :
- Nom de fichier avec timestamp
- Rotation automatique (garde les 5 derniers)
- Archivage des anciens dans `logs/archive/`
- Nettoyage automatique des archives > 30 jours

### 2. Sch√©ma de base de donn√©es (`core/schema.sql` + `core/schema.py`)

**Avant** :
- Tables cr√©√©es directement dans les scripts
- Pas de normalisation des noms
- Pas de vues ni de fonctions

**Apr√®s** :
```bash
python -m core.schema  # Cr√©e toutes les tables + indexes + triggers + vues
```

‚úÖ **Fonctionnalit√©s** :
- Sch√©ma complet en SQL
- Fonction `normalize_text()` PostgreSQL
- Triggers automatiques
- Vues pour statistiques
- Extension `pg_trgm` pour recherche rapide

### 3. Analyse de la base (`tools/analyze_database.py`)

**Avant** :
- Multiples scripts (analyze_duplicates.py, cleanup_duplicates.py, etc.)
- Analyses fragment√©es

**Apr√®s** :
```bash
python tools/analyze_database.py  # Analyse compl√®te en un seul script
```

‚úÖ **Affiche** :
- Statistiques g√©n√©rales (totaux, r√©partition H/F, ann√©es)
- Qualit√© des donn√©es (compl√©tude de chaque champ)
- Analyse des URLs (ancien/nouveau format)
- Doublons potentiels
- Recommandations

---

## üöÄ Plan de migration

### √âtape 1 : Backup de l'ancienne base

```bash
# Backup complet
pg_dump -U $POSTGRES_USER -d $POSTGRES_DB > backup_before_refactoring_$(date +%Y%m%d).sql

# Ou utiliser votre script de backup
./your_backup_script.sh
```

### √âtape 2 : Cr√©er le nouveau sch√©ma

```bash
# Option 1 : Via le script Python
python -m core.schema

# Option 2 : Directement en SQL
psql -U $POSTGRES_USER -d $POSTGRES_DB -f core/schema.sql
```

### √âtape 3 : Adapter les scripts de scraping

**√Ä faire** :
1. D√©placer `list_athletes.py` dans `scraper/`
2. D√©placer `list_clubs.py` dans `scraper/`
3. Modifier les fonctions de cr√©ation de tables pour utiliser le nouveau sch√©ma
4. Ajouter la normalisation des noms lors de l'insertion
5. Utiliser `ffa_id` au lieu de `id` pour stocker l'ID FFA

**Exemple de modification** :
```python
# AVANT
cursor.execute("""
    INSERT INTO athletes (id, name, url, birth_date, license_id, sexe, nationality)
    VALUES (%s, %s, %s, %s, %s, %s, %s)
    ON CONFLICT (id) DO UPDATE ...
""", (athlete_id, name, url, birth_date, license_id, sexe, nationality))

# APR√àS
cursor.execute("""
    INSERT INTO athletes (ffa_id, name, url, birth_date, license_id, sexe, nationality)
    VALUES (%s, %s, %s, %s, %s, %s, %s)
    ON CONFLICT (ffa_id) DO UPDATE ...
""", (athlete_id, name, url, birth_date, license_id, sexe, nationality))
# Note: normalized_name est g√©r√© automatiquement par le trigger
```

### √âtape 4 : Mettre √† jour `update_database.sh`

```bash
#!/bin/bash

LOG_FILE="logs/update.log"
TIMESTAMP="$(date +"%Y%m%d_%H%M%S")"

# ... reste du script inchang√©
```

### √âtape 5 : Tester avec un petit √©chantillon

```bash
# Scraper quelques clubs pour tester
python scraper/list_clubs.py --first-year 2025 --last-year 2025

# V√©rifier avec l'outil d'analyse
python tools/analyze_database.py
```

### √âtape 6 : Migration compl√®te (optionnelle)

Si vous voulez migrer les donn√©es existantes :

```python
# Script de migration (√† cr√©er)
# 1. Lire l'ancienne base
# 2. Ins√©rer dans la nouvelle avec ffa_id
# 3. Laisser les triggers g√©rer normalized_name
```

---

## üì¶ Fichiers √† conserver

### ‚úÖ Module core/ (nouveau)
- `core/db.py` - ‚úÖ **Connexion base de donn√©es**
- `core/config.py` - ‚úÖ **Configuration logs am√©lior√©e**
- `core/schema.py` - ‚úÖ **Gestion du sch√©ma**
- `core/schema.sql` - ‚úÖ **D√©finition du sch√©ma SQL**
- `core/__init__.py` - ‚úÖ **Module package**

### ‚úÖ Modules scraper/ et tools/
- `scraper/list_athletes.py` - ‚úÖ **Scraping athl√®tes**
- `scraper/list_clubs.py` - ‚úÖ **Scraping clubs**
- `tools/analyze_database.py` - ‚úÖ **Script d'analyse consolid√©**
- `scraper/__init__.py` - ‚úÖ **Module package**
- `tools/__init__.py` - ‚úÖ **Module package**

### üìù √Ä mettre √† jour
- `update_database.sh` - √Ä adapter pour le module core
- `README.md` - √Ä mettre √† jour

### üóëÔ∏è √Ä supprimer (obsol√®tes)
- `analyze_duplicates.py`
- `cleanup_duplicates.py`
- `analyze_id_conflicts.py`
- `update_missing_licenses.py`
- `update_old_urls.py`
- `MIGRATION_LICENSE_ID.md`

---

## üìù Modification de l'API

Pour utiliser la recherche optimis√©e avec `normalized_name` :

```python
# AVANT
normalized_query = ' '.join(unidecode(name).lower().strip().split())
query_parts = normalized_query.split()
where_clause = " AND ".join(["LOWER(name) LIKE %s" for _ in query_parts])

# APR√àS
normalized_query = ' '.join(unidecode(name).lower().strip().split())
query_parts = normalized_query.split()
where_clause = " AND ".join(["normalized_name LIKE %s" for _ in query_parts])

# Bonus : tri par pertinence
query = f"""
SELECT id, ffa_id, name, url, birth_date, license_id, sexe, nationality
FROM athletes
WHERE {where_clause}
ORDER BY similarity(normalized_name, %s) DESC
LIMIT 25
"""
```

---

## ‚úÖ Checklist de migration

- [ ] Backup de l'ancienne base effectu√©
- [x] **Module `core/` cr√©√© avec db, config, schema**
- [x] **Imports mis √† jour dans tous les fichiers**
- [x] **`update_database.sh` mis √† jour pour utiliser `python3 -m scraper.*`**
- [x] **Fichier `log.txt` hardcod√© supprim√© (utilise syst√®me de logging centralis√©)**
- [ ] Nouveau sch√©ma cr√©√© (`python -m core.schema`)
- [ ] Scripts de scraping adapt√©s pour utiliser `ffa_id`
- [ ] Tests effectu√©s sur un petit √©chantillon
- [ ] API mise √† jour pour utiliser `normalized_name` et `ffa_id`
- [ ] Anciens scripts obsol√®tes supprim√©s
- [ ] Documentation (`README.md`) mise √† jour

---

## üéâ B√©n√©fices attendus

1. **Performance** : Recherches jusqu'√† 10x plus rapides avec les index trigram
2. **Robustesse** : Plus de conflits d'IDs possibles
3. **Maintenabilit√©** : Code organis√© en modules
4. **Tra√ßabilit√©** : Logs horodat√©s avec archivage automatique
5. **Qualit√©** : Indicateurs de qualit√© des donn√©es facilement accessibles
6. **P√©rennit√©** : R√©sistant aux futurs changements du site FFA

---

## üìû Support

Pour toute question ou probl√®me lors de la migration :
1. Consulter les logs dans `logs/`
2. Lancer `python tools/analyze_database.py` pour diagnostiquer
3. Restaurer le backup si n√©cessaire
